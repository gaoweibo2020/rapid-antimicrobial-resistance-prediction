{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "\n",
    "#SNIP algrithm\n",
    "def snip(y, iterations=20, decreasing=True):\n",
    "    n = len(y)\n",
    "    d = int(decreasing)\n",
    "\n",
    "    xo = np.empty(n, dtype=np.float64)\n",
    "    xy = np.array(y, dtype=np.float64)\n",
    "\n",
    "    k = int(iterations)\n",
    "\n",
    "    if d:\n",
    "        for i in range(k, 0, -1):\n",
    "            for j in range(i, n - i):\n",
    "                a = xy[j]\n",
    "                b = (xy[j - i] + xy[j + i]) / 2\n",
    "                if b < a:\n",
    "                    a = b\n",
    "                xo[j] = a\n",
    "\n",
    "            for j in range(i, n - i):\n",
    "                xy[j] = xo[j]\n",
    "    else:\n",
    "        for i in range(1, k + 1):\n",
    "            for j in range(i, n - i):\n",
    "                a = xy[j]\n",
    "                b = (xy[j - i] + xy[j + i]) / 2\n",
    "                if b < a:\n",
    "                    a = b\n",
    "                xo[j] = a\n",
    "\n",
    "            for j in range(i, n - i):\n",
    "                xy[j] = xo[j]\n",
    "\n",
    "    xo = xy.copy()\n",
    "\n",
    "    return xo\n",
    "\n",
    "\n",
    "# intensity calibration\n",
    "def toc(y_data):\n",
    "    return y_data / y_data.sum()\n",
    "\n",
    "\n",
    "def interpolate(data, boundary, mask, kind):\n",
    "    if kind != None:\n",
    "        f = interp1d(data[0],\n",
    "                     data[1],\n",
    "                     kind=kind,\n",
    "                     bounds_error=False,\n",
    "                     fill_value=0,\n",
    "                     assume_sorted=False)\n",
    "    new_data = []\n",
    "    if kind != None:\n",
    "        for i in range(len(boundary)):\n",
    "            new_data.append(f(boundary[i]))\n",
    "    else:\n",
    "        for i in range(len(boundary)):\n",
    "            if i + 1 == len(boundary):\n",
    "                break\n",
    "            if ((data[0] < boundary[i + 1]) &\n",
    "                (data[0] > boundary[i])).astype('int').sum() != 0:\n",
    "                new_data.append(data[1][(data[0] < boundary[i + 1])\n",
    "                                        & (data[0] > boundary[i])].max())\n",
    "            else:\n",
    "                new_data.append(0)\n",
    "    new_data = np.array(new_data)\n",
    "\n",
    "    new_data[new_data < 0] = 0\n",
    "    if mask is not None:\n",
    "        new_data = new_data[mask]\n",
    "    return new_data\n",
    "\n",
    "\n",
    "def SampleGenerator(data, boundary, housekeeping, mask=None, kind=None, shuffle=True):\n",
    "    if shuffle:\n",
    "        data = data.sample(frac=1).reset_index(drop=True)\n",
    "    ids = data['ID']\n",
    "    x = []\n",
    "    for id in ids:\n",
    "        x.append(load_mass('../data/' + id + '.txt', boundary, mask, kind, housekeeping))\n",
    "    x = np.array(x)\n",
    "\n",
    "    label = data['Class']\n",
    "    y = np.zeros_like(label)\n",
    "    y[label == 'S'] = 1\n",
    "    y = y.astype('float')\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def load_mass(path, boundary, mask, kind,housekeeping):\n",
    "    data = [[], []]\n",
    "\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        # remove comments\n",
    "        lines = lines[8:]\n",
    "        for line in lines:\n",
    "            data[0].append(float(line.split(' ')[0]))\n",
    "            data[1].append(float(line.split(' ')[1]))\n",
    "    data = np.array(data)\n",
    "\n",
    "    if housekeeping is not None:\n",
    "        min_diff = 1e5\n",
    "        for item in data[0]:\n",
    "            diff = housekeeping - item\n",
    "            if np.abs(diff) < np.abs(min_diff):\n",
    "                min_diff = diff\n",
    "        data[0] = data[0] + min_diff\n",
    "\n",
    "    # variance stabilising\n",
    "    data[1] = np.sqrt(data[1])\n",
    "    # smoothing\n",
    "    data[1] = savgol_filter(data[1], window_length=21,\n",
    "                            polyorder=3)\n",
    "    data[1][data[1] < 0] = 0\n",
    "    # baseline removal\n",
    "    data[1] = data[1] - snip(data[1].copy())\n",
    "    # intensity calibration\n",
    "    data[1] = toc(data[1])\n",
    "\n",
    "    #bin\n",
    "    new_data = interpolate(data, boundary, mask, kind=kind)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "data = pd.read_csv('../data/data.csv')\n",
    "data = data[(data.Date == '20221112') | (data.Date == '20221130-24h') | (data.Date == '20221220-24h')]\n",
    "test_ptient_data = data[data.Date == '20221220-24h']\n",
    "train_data = data.drop(test_ptient_data.index).reset_index(drop=True)\n",
    "test_data = test_ptient_data.reset_index(drop=True)\n",
    "boundary = np.arange(0, 1801) * 5 + 2000\n",
    "housekeeping = 4428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(SVC(),\n",
    "                    param_grid={\n",
    "                        \"kernel\": ['linear', 'rbf'],\n",
    "                        \"gamma\": [0.1, 1, 10],\n",
    "                        \"C\": [0.1, 0.5, 1, 5, 10],\n",
    "                        \"max_iter\": [1000, 5000, 10000, 50000, 100000]\n",
    "                    },\n",
    "                    cv=5)\n",
    "x_train, y_train = SampleGenerator(train_data,boundary,housekeeping)\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"The best parameters are %s with a score of %0.2f\" %\n",
    "      (grid.best_params_, grid.best_score_))\n",
    "best_model = SVC(probability=True, **grid.best_params_)\n",
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "x_test, y_test = SampleGenerator(test_data, boundary, housekeeping)\n",
    "expected = y_test\n",
    "predicted = best_model.predict(x_test)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "# auc = metrics.roc_auc_score(y_test, predicted)\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM+L1\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "grid = GridSearchCV(LinearSVC(penalty='l1',\n",
    "                              loss='squared_hinge',\n",
    "                              dual=False,\n",
    "                              fit_intercept=True),\n",
    "                    param_grid={\n",
    "                        \"C\": [0.1, 0.5, 1, 5, 10],\n",
    "                        \"max_iter\": [1000, 5000, 10000, 50000, 100000]\n",
    "                    },\n",
    "                    cv=5)\n",
    "x_train, y_train = SampleGenerator(train_data, boundary, housekeeping)\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"The best parameters are %s with a score of %0.2f\" %\n",
    "      (grid.best_params_, grid.best_score_))\n",
    "best_model = LinearSVC(penalty='l1',\n",
    "                       loss='squared_hinge',\n",
    "                       dual=False,\n",
    "                       fit_intercept=True,\n",
    "                       **grid.best_params_)\n",
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "x_test, y_test = SampleGenerator(test_data, boundary, housekeeping)\n",
    "expected = y_test\n",
    "predicted = best_model.predict(x_test)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "# auc = metrics.roc_auc_score(y_test, predicted)\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(),\n",
    "                    param_grid={\n",
    "                        \"penalty\": ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                        \"solver\":\n",
    "                        ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                        \"C\": [0.1, 0.5, 1, 5, 10],\n",
    "                        \"max_iter\": [1000, 5000, 10000, 50000, 100000]\n",
    "                    },\n",
    "                    cv=5)\n",
    "x_train, y_train = SampleGenerator(train_data, boundary, housekeeping)\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"The best parameters are %s with a score of %0.2f\" %\n",
    "      (grid.best_params_, grid.best_score_))\n",
    "best_model = LogisticRegression(\n",
    "                                **grid.best_params_)\n",
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "x_test, y_test = SampleGenerator(test_data, boundary, housekeeping)\n",
    "expected = y_test\n",
    "predicted = best_model.predict(x_test)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "# auc = metrics.roc_auc_score(y_test, predicted)\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    MLPClassifier(),\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [\n",
    "            (1024, 512, 256),(2500, 1250, 525),(2500, 2500, 2500),(512, 256, 128),(256, 256, 128)],\n",
    "        \"activation\": [\n",
    "            'relu',\n",
    "            'identity',\n",
    "            'logistic',\n",
    "            'tanh',\n",
    "        ],\n",
    "        \"solver\": ['lbfgs', 'sgd', 'adam'],\n",
    "        \"max_iter\": [1000, 5000, 10000, 50000, 100000]\n",
    "    },\n",
    "    cv=5)\n",
    "x_train, y_train = SampleGenerator(train_data, boundary, housekeeping)\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"The best parameters are %s with a score of %0.2f\" %\n",
    "      (grid.best_params_, grid.best_score_))\n",
    "best_model = MLPClassifier(**grid.best_params_)\n",
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "x_test, y_test = SampleGenerator(test_data, boundary, housekeeping)\n",
    "expected = y_test\n",
    "predicted = best_model.predict(x_test)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "# auc = metrics.roc_auc_score(y_test, predicted)\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08bca10ddddfa5ec2218c3ca88431b2016326f124aa4b8d7dee67ba697a17c3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
